{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f04bc3",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26128f1a",
   "metadata": {},
   "source": [
    "## Step 2: Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sales transaction data\n",
    "print(\"Loading sales data...\")\n",
    "data = pd.read_csv(\"../Data/Sales.csv\", sep=\";\")\n",
    "print(f\"âœ“ Data loaded successfully\")\n",
    "print(f\"  Shape: {data.shape}\")\n",
    "print(f\"  Columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f53ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of raw data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd0da3",
   "metadata": {},
   "source": [
    "## Step 3: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e38798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\"*60)\n",
    "print(\" DATA EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal rows: {len(data)}\")\n",
    "print(f\"Total columns: {len(data.columns)}\")\n",
    "print(f\"\\nUnique transactions (BillNo): {data['BillNo'].nunique() if 'BillNo' in data.columns else 'N/A'}\")\n",
    "print(f\"Unique items: {data['Itemname'].nunique() if 'Itemname' in data.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbd67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14565",
   "metadata": {},
   "source": [
    "## Step 4: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdafb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset of data for faster processing (10,000 rows)\n",
    "# For full dataset, remove this line\n",
    "print(\"\\nSubsetting data to 10,000 rows for faster processing...\")\n",
    "data = data.iloc[:10000, :]\n",
    "print(f\"âœ“ Using {len(data)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant columns for association rule mining\n",
    "print(\"\\nSelecting relevant columns...\")\n",
    "data = data[['BillNo', 'Itemname']]\n",
    "print(f\"âœ“ Selected columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "initial_rows = len(data)\n",
    "data.dropna(inplace=True)\n",
    "rows_removed = initial_rows - len(data)\n",
    "print(f\"âœ“ Removed {rows_removed} rows with missing values\")\n",
    "print(f\"âœ“ Remaining rows: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55067ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned data sample\n",
    "print(\"\\nCleaned data sample:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557853d",
   "metadata": {},
   "source": [
    "## Step 5: Transform to Transaction Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fae20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group items by transaction (BillNo)\n",
    "# Each row will contain a list of items purchased in one transaction\n",
    "print(\"\\nGrouping items by transaction...\")\n",
    "transactions = data.groupby(\"BillNo\")[\"Itemname\"].apply(list).reset_index()\n",
    "print(f\"âœ“ Created {len(transactions)} transactions\")\n",
    "print(f\"âœ“ Average items per transaction: {data.groupby('BillNo').size().mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transaction format\n",
    "print(\"\\nTransaction Format (first 5 transactions):\")\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e44447",
   "metadata": {},
   "source": [
    "## Step 6: Binary Encoding (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f672e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transaction list format to binary matrix\n",
    "# Each column represents an item, each row is a transaction\n",
    "# True/1 means item was purchased, False/0 means it wasn't\n",
    "print(\"\\nEncoding transactions to binary matrix...\")\n",
    "te = TransactionEncoder()\n",
    "transactions_bool_list = te.fit(transactions[\"Itemname\"]).transform(transactions[\"Itemname\"])\n",
    "\n",
    "# Create dataframe with encoded transactions\n",
    "data_transaction = pd.DataFrame(transactions_bool_list, columns=te.columns_)\n",
    "print(f\"âœ“ Binary encoding completed\")\n",
    "print(f\"âœ“ Matrix shape: {data_transaction.shape}\")\n",
    "print(f\"âœ“ Number of unique items: {data_transaction.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all items (columns)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nAll items in dataset:\")\n",
    "print(data_transaction.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of binary encoded data\n",
    "print(\"\\nBinary Encoded Transaction Matrix (first 10 rows):\")\n",
    "data_transaction.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10295c05",
   "metadata": {},
   "source": [
    "## Step 7: Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b84a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the processed data\n",
    "print(\"=\"*60)\n",
    "print(\" DATA VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for any issues\n",
    "print(f\"\\nâœ“ No missing values: {data_transaction.isnull().sum().sum() == 0}\")\n",
    "print(f\"âœ“ All values are boolean: {data_transaction.dtypes.unique()[0] == bool}\")\n",
    "print(f\"âœ“ Matrix dimensions: {data_transaction.shape[0]} transactions Ã— {data_transaction.shape[1]} items\")\n",
    "\n",
    "# Calculate sparsity (how sparse is the matrix)\n",
    "total_cells = data_transaction.shape[0] * data_transaction.shape[1]\n",
    "true_cells = data_transaction.sum().sum()\n",
    "sparsity = (1 - true_cells / total_cells) * 100\n",
    "print(f\"âœ“ Matrix sparsity: {sparsity:.2f}% (typical for transaction data)\")\n",
    "print(f\"âœ“ Average items per transaction: {data_transaction.sum(axis=1).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e503c0",
   "metadata": {},
   "source": [
    "## Step 8: Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed binary matrix to CSV\n",
    "output_path = \"../Data/processed_transactions.csv\"\n",
    "print(f\"\\nSaving processed data to {output_path}...\")\n",
    "data_transaction.to_csv(output_path, index=False)\n",
    "print(\"âœ“ Processed data saved successfully!\")\n",
    "print(f\"âœ“ File size: {data_transaction.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aa9a1",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*70)\n",
    "print(\" PREPROCESSING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"   â€¢ Original data: {initial_rows} rows\")\n",
    "print(f\"   â€¢ After cleaning: {len(data)} rows\")\n",
    "print(f\"   â€¢ Unique transactions: {len(transactions)}\")\n",
    "print(f\"   â€¢ Unique items: {data_transaction.shape[1]}\")\n",
    "print(f\"   â€¢ Binary matrix: {data_transaction.shape[0]} Ã— {data_transaction.shape[1]}\")\n",
    "print(f\"   â€¢ Output file: processed_transactions.csv\")\n",
    "print(f\"\\nâœ“ Data is now ready for Apriori and FP-Growth algorithms!\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba3ddf",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The processed data has been saved to `../Data/processed_transactions.csv`\n",
    "\n",
    "**You can now run:**\n",
    "1. `Apriori_Model.ipynb` - For Apriori algorithm\n",
    "2. `FPGrowth_Model.ipynb` - For FP-Growth algorithm\n",
    "\n",
    "Both models will load the preprocessed data automatically."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
